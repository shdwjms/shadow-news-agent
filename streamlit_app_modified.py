# Shadow Intel Agent - NewsAPI Version (modified with new UI styles)
import streamlit as st
import requests
import json
from datetime import datetime, timedelta

# Page configuration
st.set_page_config(
    page_title="Shadow Intel Agent",
    page_icon="üïµÔ∏è",
    layout="wide"
)

# -------------------------------------------------------------
# Custom styling
#
# Define CSS variables and fonts to match the requested palette:
# - Primary color: Shadow Violet (#5F4B8B)
# - Background: #F2F4F7
# - Accent colors: Matcha Green (#B7DD79) or Butter Yellow (#FFD56B)
# - Fonts: Palettone for headings (with sensible fallback), Raleway/Inter for body text
# - Sidebar with a translucent blur
# - Rounded buttons with emoji labels
#
custom_css = """
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Raleway:wght@400;600;700&display=swap');

/* Colour palette variables */
:root {
  --primary-color: #5F4B8B;
  --background-color: #F2F4F7;
  --accent-green: #B7DD79;
  --accent-yellow: #FFD56B;
}

/* Base styles */
html, body, [class*="css"]  {
  background-color: var(--background-color) !important;
  font-family: 'Inter', 'Raleway', sans-serif;
}

h1, h2, h3, h4 {
  font-family: 'Palettone', 'Inter', sans-serif;
  color: var(--primary-color);
}

/* Style the Streamlit buttons */
.stButton > button {
  background-color: var(--primary-color);
  color: white;
  border: none;
  border-radius: 1rem;
  padding: 0.5rem 1rem;
  font-size: 1rem;
  font-family: 'Inter', 'Raleway', sans-serif;
}

/* Sidebar styling: translucent with blur */
div[data-testid="stSidebar"] {
  background: rgba(255, 255, 255, 0.6) !important;
  backdrop-filter: blur(8px);
}
</style>
"""

# Inject custom CSS into the app
st.markdown(custom_css, unsafe_allow_html=True)

# -------------------------------------------------------------
# Titles and headers
st.title("üïµÔ∏è Shadow Intel Agent")
st.subheader("üì∞ AI & Tech Intelligence Gathering")

# Tagline conveying personality
st.caption("AI, –Ω–æ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä.")

# Session state for counting searches
if 'search_count' not in st.session_state:
    st.session_state.search_count = 0

# NewsAPI key (hard-coded for demonstration)
NEWSAPI_KEY = "cdd83a93db6344bc95c7d5eedd117c02"

# Topic selection
query_options = {
    "AI investing": "artificial intelligence investing OR AI stocks",
    "AI market": "artificial intelligence market trends", 
    "AI stocks": "AI stocks OR artificial intelligence companies",
    "Nvidia": "Nvidia OR NVDA stock",
    "OpenAI": "OpenAI OR ChatGPT",
    "ChatGPT": "ChatGPT OR OpenAI",
    "Tesla AI": "Tesla artificial intelligence OR Tesla FSD"
}

selected_topic = st.selectbox(
    "üì∞ –ò–∑–±–µ—Ä–∏ —Ç–µ–º–∞:",
    list(query_options.keys())
)

query = query_options[selected_topic]

# Filters
col1, col2 = st.columns(2)
with col1:
    days_back = st.slider("üìÖ –ù–æ–≤–∏–Ω–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ –¥–Ω–∏:", 1, 30, 7)
with col2:
    language = st.selectbox("üåç –ï–∑–∏–∫:", ["en", "bg"], index=0)

# Primary API method
def search_with_newsapi(api_key, query, days_back, language):
    """
    Fetch articles from NewsAPI based on the query and filters.
    """
    from_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')

    url = "https://newsapi.org/v2/everything"
    params = {
        'q': query,
        'from': from_date,
        'language': language,
        'sortBy': 'relevancy',
        'pageSize': 20,
        'apiKey': api_key
    }

    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"API –≥—Ä–µ—à–∫–∞: {str(e)}")
        return None

# Alternative method without API
def search_alternative():
    """
    Use public RSS feeds when no API key is provided.
    """
    try:
        # TechCrunch RSS for AI news
        rss_urls = {
            "TechCrunch": "https://techcrunch.com/category/artificial-intelligence/feed/",
            "VentureBeat": "https://feeds.feedburner.com/venturebeat/SZYF",
            "AI News": "https://www.artificialintelligence-news.com/feed/"
        }

        st.info("üîÑ –ò–∑–ø–æ–ª–∑–≤–∞–º –∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏ –∏–∑—Ç–æ—á–Ω–∏—Ü–∏ (RSS feeds)...")

        results = []
        for source, url in rss_urls.items():
            try:
                import feedparser
                feed = feedparser.parse(url)

                for entry in feed.entries[:5]:  # First 5 from each feed
                    results.append({
                        'title': entry.title,
                        'description': entry.get('summary', '–ù—è–º–∞ –æ–ø–∏—Å–∞–Ω–∏–µ'),
                        'url': entry.link,
                        'source': source,
                        'publishedAt': entry.get('published', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞ –¥–∞—Ç–∞')
                    })
            except:
                continue

        return {'articles': results, 'totalResults': len(results)}

    except ImportError:
        st.error("‚ùå –ó–∞ –∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏—è –º–µ—Ç–æ–¥ –µ –Ω—É–∂–µ–Ω feedparser: pip install feedparser")
        return None

# Search button
if st.button("üîç Decode News"):
    st.session_state.search_count += 1

    with st.spinner("–¢—ä—Ä—Å—è –∞–∫—Ç—É–∞–ª–Ω–∏ –Ω–æ–≤–∏–Ω–∏... üì∞"):

        if NEWSAPI_KEY:
            # Use NewsAPI
            data = search_with_newsapi(NEWSAPI_KEY, query, days_back, language)
        else:
            # Use RSS alternative
            data = search_alternative()

        if data and data.get('articles'):
            articles = data['articles']
            total = data.get('totalResults', len(articles))

            st.success(f"‚úÖ –ù–∞–º–µ—Ä–µ–Ω–∏ —Å–∞ {len(articles)} –Ω–æ–≤–∏–Ω–∏ –æ—Ç –æ–±—â–æ {total}")

            # Display results
            for i, article in enumerate(articles):
                with st.expander(f"üì∞ {article['title'][:80]}..."):

                    col1, col2 = st.columns([3, 1])

                    with col1:
                        st.markdown(f"### {article['title']}")
                        st.write(article.get('description', '–ù—è–º–∞ –æ–ø–∏—Å–∞–Ω–∏–µ'))

                        if article.get('publishedAt'):
                            try:
                                pub_date = datetime.fromisoformat(article['publishedAt'].replace('Z', '+00:00'))
                                st.caption(f"üìÖ {pub_date.strftime('%d.%m.%Y %H:%M')}")
                            except:
                                st.caption(f"üìÖ {article['publishedAt']}")

                    with col2:
                        if article.get('urlToImage'):
                            try:
                                st.image(article['urlToImage'], width=150)
                            except:
                                st.write("üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—ä–ø–Ω–æ")

                        st.markdown(f"**–ò–∑—Ç–æ—á–Ω–∏–∫:** {article.get('source', {}).get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')}")

                    st.markdown(f"üîó [–ü—Ä–æ—á–µ—Ç–∏ –ø—ä–ª–Ω–∞—Ç–∞ —Å—Ç–∞—Ç–∏—è]({article['url']})")
                    st.divider()
        else:
            st.warning("‚ö†Ô∏è –ù—è–º–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏")
            if not NEWSAPI_KEY:
                st.info("üí° –î–æ–±–∞–≤–∏ API –∫–ª—é—á –∑–∞ –ø–æ-–¥–æ–±—Ä–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏!")

# Statistics
if st.session_state.search_count > 0:
    st.info(f"üìä –ù–∞–ø—Ä–∞–≤–µ–Ω–∏ –∑–∞—è–≤–∫–∏ —Ç–∞–∑–∏ —Å–µ—Å–∏—è: {st.session_state.search_count}")

    if NEWSAPI_KEY and st.session_state.search_count > 80:
        st.warning("‚ö†Ô∏è –ë–ª–∏–∑–æ –¥–æ –ª–∏–º–∏—Ç–∞ –æ—Ç 100 –∑–∞—è–≤–∫–∏/–¥–µ–Ω!")

# Direct links (backup)
st.divider()
st.subheader("üîó –î–∏—Ä–µ–∫—Ç–Ω–∏ –∏–∑—Ç–æ—á–Ω–∏—Ü–∏ (–≤–∏–Ω–∞–≥–∏ —Ä–∞–±–æ—Ç—è—Ç)")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("### üìä –§–∏–Ω–∞–Ω—Å–∏")
    st.markdown("- [Yahoo Finance](https://finance.yahoo.com)")
    st.markdown("- [MarketWatch](https://www.marketwatch.com)")
    st.markdown("- [Reuters](https://www.reuters.com)")

with col2:
    st.markdown("### ü§ñ AI –ù–æ–≤–∏–Ω–∏")
    st.markdown("- [VentureBeat AI](https://venturebeat.com/ai/)")
    st.markdown("- [The Verge AI](https://www.theverge.com/ai-artificial-intelligence)")
    st.markdown("- [TechCrunch AI](https://techcrunch.com/category/artificial-intelligence/)")

with col3:
    st.markdown("### üíº –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏")
    st.markdown("- [Seeking Alpha](https://seekingalpha.com)")
    st.markdown("- [Benzinga](https://www.benzinga.com)")
    st.markdown("- [Bloomberg Tech](https://www.bloomberg.com/technology)")

# Footer
st.divider()
st.caption("Made with ‚òª and sarcasm by Shadow & James")

# Sidebar information with blur and translucent styling (CSS applied above)
with st.sidebar:
    st.header("üÜï –ù–æ–≤–∞ –≤–µ—Ä—Å–∏—è —Å NewsAPI!")
    st.success("‚úÖ –ù—è–º–∞ –±–ª–æ–∫–∏—Ä–∞–Ω–∏—è!")
    st.success("‚úÖ 100 –±–µ–∑–ø–ª–∞—Ç–Ω–∏ –∑–∞—è–≤–∫–∏/–¥–µ–Ω")
    st.success("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–∞–Ω–∏ –¥–∞–Ω–Ω–∏")
    st.success("‚úÖ –§–∏–ª—Ç—Ä–∏ –ø–æ –¥–∞—Ç–∞ –∏ –µ–∑–∏–∫")

    st.header("‚ÑπÔ∏è –ö–∞–∫ —Ä–∞–±–æ—Ç–∏:")
    st.write("""
    1. üîë –í—ä–≤–µ–¥–∏ API –∫–ª—é—á (–µ–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ)
    2. üéØ –ò–∑–±–µ—Ä–∏ —Ç–µ–º–∞
    3. üìÖ –ù–∞—Å—Ç—Ä–æ–π —Ñ–∏–ª—Ç—Ä–∏—Ç–µ
    4. üîç –ù–∞—Ç–∏—Å–Ω–∏ —Ç—ä—Ä—Å–µ–Ω–µ
    5. üì∞ –†–∞–∑–≥–ª–µ–¥–∞–π –Ω–æ–≤–∏–Ω–∏—Ç–µ!
    """)

    st.header("üí° –ë–µ–∑ API –∫–ª—é—á?")
    st.write("–©–µ –∏–∑–ø–æ–ª–∑–≤–∞–º–µ RSS feeds, –Ω–æ —Å –ø–æ-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏.")

    if st.button("üîÑ –ù—É–ª–∏—Ä–∞–π –±—Ä–æ—è—á–∞"):
        st.session_state.search_count = 0
        st.rerun()